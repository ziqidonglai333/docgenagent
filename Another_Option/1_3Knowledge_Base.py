# å¯¼å…¥ç›¸å…³çš„åŒ…
import streamlit as st
import os
import pickle
import nltk
import faiss
from langchain_community.document_loaders import DirectoryLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from zhipuai import ZhipuAI
from sentence_transformers import SentenceTransformer

# *-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*

# è®¾ç½®é¡µé¢å¸ƒå±€
st.set_page_config(page_title = "çŸ¥è¯†åº“",
                   page_icon = "ğŸ›„",
                   layout= "wide",
                   initial_sidebar_state="expanded")

st.markdown("# çŸ¥è¯†åº“")

with st.sidebar:
    st.markdown("# çŸ¥è¯†åº“")
    
    kd_temperature = st.slider(label= "æ¨¡å‹æ¸©åº¦",
                max_value=1.0,
                min_value=0.0,
                step= 0.1,
                value= 0.8)
    
    field = st.text_area(label = "æ‰€å±é¢†åŸŸ",placeholder="è´¢åŠ¡é¢†åŸŸã€ä¸­å›½å®è§‚ç»æµã€é‡‘èã€å¸‚åœºåˆ†æã€ä¼ä¸šç®¡ç†ã€æˆ˜ç•¥è§„åˆ’ç­‰")
    know_db_gene_button = st.button(label = "çŸ¥è¯†åº“ç”Ÿæˆ/åŠ è½½")
    retri_button = st.button(label = "æ£€ç´¢å†…å®¹")
    answ_button = st.button(label = "ç”Ÿæˆå›å¤")
    clear_button = st.button(label = "æ¸…é™¤æ£€ç´¢ç»“æœ")

embedding_model = SentenceTransformer("/root/autodl-tmp/bge-large-zh-v1.5")

def load_spilt_embedding_txt(kd_source_file_path):   
    '''
    è¯¥å‡½æ•°çš„åŠŸèƒ½æ˜¯å¯¹æ–‡ä»¶å¤¹å†…å…¨éƒ¨TXTæ–‡æ¡£è¿›è¡Œåˆ†å‰²ï¼Œå®Œæˆå‘é‡åŒ–å­˜å‚¨.
    kd_source_file_path:éœ€è¦å‘é‡åŒ–çš„txtæ–‡æ¡£æ–‡ä»¶å¤¹è·¯å¾„
    '''
    
    situation = ""
    split_situation = []
    faiss_situation =""
    
    father_path = os.path.dirname(kd_source_file_path)
    kd_source_file_name = os.path.basename(kd_source_file_path)
    pkl_path = os.path.join(father_path,f"{kd_source_file_name}_splittxt.pkl")
    faiss_path = os.path.join(father_path,f"{kd_source_file_name}_faissindex.faiss")
    if (os.path.exists(pkl_path)==True) and(os.path.exists(faiss_path)==True):
        situation = f"{pkl_path}å’Œ{faiss_path}ä¸¤ä¸ªæ–‡ä»¶å·²å­˜åœ¨ï¼Œå¦‚åŸå§‹æ–‡æ¡£æœ‰æ›´æ–°ï¼Œéœ€è¦é‡æ–°åŠ è½½ã€åˆ†å‰²å’Œå‘é‡åŒ–æ–‡æ¡£ï¼Œè¯·åˆ é™¤è¿™ä¸¤ä¸ªæ–‡ä»¶åé‡æ–°æ‰§è¡Œ"
        print(situation)
        print("--"*33)
        with open (pkl_path,"rb") as f:
            contents = pickle.load(f)
        split_situation =[f"{pkl_path}æœ‰{len(contents)}æ¡æ•°æ®",f"ç¬¬ä¸€æ¡æ•°æ®ä¸ºï¼š{contents[0]}",f"æœ€åä¸€æ¡æ•°æ®ä¸ºï¼š{contents[-1]}"]
        print(split_situation[0])
        print("--"*33)
        print(split_situation[1])
        print("--"*33)
        print(split_situation[2])        

        faiss_index =faiss.read_index(faiss_path)
    
        faiss_situation = "å¯¹åº”çš„å‘é‡æ•°æ®åº“faiss_indexå·²ç»åŠ è½½"
        print("--"*33)
        print(faiss_situation)
        
    else:
        loader = DirectoryLoader(kd_source_file_path,glob="**/*.txt",show_progress=True)
        content = loader.load()
        situation = "å·²å®ŒæˆçŸ¥è¯†åº“åŸæ–‡æ¡£åŠ è½½"
        print(situation)
        # ----------------------------------
        # ç”¨RecursiveCharacterTextSplitteråˆ‡å‰²
        
        textsplitter = RecursiveCharacterTextSplitter(
            chunk_size = 200,
            chunk_overlap = 30,
            length_function=len,
            is_separator_regex=False,
        )
        spli_docs = textsplitter.create_documents([i.page_content for i in content])
        contents = [i.page_content for i in spli_docs]
        
        with open(pkl_path,"wb") as file:
            pickle.dump(contents,file)
        split_situation = [f"{pkl_path}æ–‡ä»¶å·²ç»ç”Ÿæˆï¼Œå…±è®¡{len(contents)}æ¡æ•°æ®",f"ç¬¬ä¸€æ¡æ•°æ®æ˜¯{contents[0]}",f"æœ€åä¸€æ¡æ•°æ®æ˜¯{contents[-1]}"]
        print(split_situation[0])
        print("--"*33)
        print(split_situation[1])
        print("--"*33)
        print(split_situation[2])
    
        # ----------------------------------
        # å¯¹åˆ‡å‰²åçš„æ–‡æœ¬å‘é‡åŒ–

        embedding_content = embedding_model.encode(contents)

        # å°†æ–‡æœ¬å‘é‡åŒ–æ•°æ®åŠ å…¥faissæ•°æ®åº“
        faiss_index = faiss.IndexFlatL2(embedding_model.get_sentence_embedding_dimension())
        faiss_index.add(embedding_content)
        faiss.write_index(faiss_index,faiss_path)
        
        faiss_situation = f"å¯¹åº”çš„å‘é‡æ•°æ®åº“faiss_indexå·²ç»åŠ è½½"
        print("--"*33)
        print(faiss_situation)


    return {"situation":situation,"split_situation":split_situation,"faiss_situation":faiss_situation,"faiss_index":faiss_index,"text_contents":contents}

# ----------------------------------

def knoledge_retri(faiss_path,txt_path,squery,k):   
    '''
    è¯¥å‡½æ•°çš„åŠŸèƒ½æ˜¯å¯¹å®ç°çŸ¥è¯†åº“æœç´¢,æ ¹æ®æ£€ç´¢ç»“æœå›ç­”é—®é¢˜
    faiss_path:å‘é‡æ•°æ®åº“æ–‡ä»¶è·¯å¾„
    txt_pathï¼šåˆ‡å‰²æ–‡æœ¬æ•°æ®æ–‡ä»¶è·¯å¾„
    squery:éœ€è¦å¤§æ¨¡å‹å›ç­”çš„é—®é¢˜
    k:æ£€ç´¢åï¼Œä»æ£€ç´¢æ’åºç»“æœä¸­å½•å–çš„æ•°é‡
    ''' 

    faiss_db = faiss.read_index(faiss_path)
    retr = faiss_db.search(embedding_model.encode(squery),k)
    print ("***"*39)
    dist = retr[0]
    index =retr[1]
    print ("è·ç¦»ï¼š",dist)
    print ("è·ç¦»ï¼š",type(dist))
    print ("ç´¢å¼•",index)
    print ("è·ç¦»ï¼š",type(index))
    retre_result = ""
    with open (txt_path,"rb") as f:
            contents = pickle.load(f)
    for i in index[0]:
        xx = contents[i]+"/n/n"
        retre_result = retre_result+xx
    return  retre_result

# ----------------------------------

def RAG_Answ(squery,retre_result,kd_temperature,field):
    # è®¾ç½®å¤§æ¨¡å‹æç¤ºè¯å’Œapi_key
    sys_prompt = f"""ä½ æ˜¯ä¸€åèµ„æ·±çš„{field}é¢†åŸŸä¸“å®¶ï¼Œæ‹¥æœ‰è¶…è¿‡15å¹´çš„è¡Œä¸šç»éªŒã€‚"""    
    user_prompt =  f"""ä½ ä»»åŠ¡æ˜¯çš„æ ¹æ®{retre_result}å†…å®¹ï¼Œå›ç­” {squery}çš„é—®é¢˜ï¼Œå…·ä½“å›å¤è§[å›å¤è¦æ±‚]ã€‚
        [å›å¤è¦æ±‚]ï¼š
         ---è¯·ä¸¥æ ¼æŒ‰ç…§{retre_result}å†…å®¹è¦æ±‚å›ç­”é—®é¢˜ï¼›
         ---å¿…è¦æ—¶å¯æ ¹æ®ä½ è‡ªå·±çš„çŸ¥è¯†å›ç­”é—®é¢˜ï¼Œåœ¨ä½¿ç”¨ä½ è‡ªæœ‰çš„çŸ¥è¯†æ—¶ï¼Œéœ€æ ‡æ˜'æ ¹æ®æˆ‘å·²æœ‰ç»éªŒ......'ï¼Œå¹¶å°†è¿™äº›å­—ä½“åŠ é»‘ã€æ–œä½“æ˜¾ç¤ºï¼›
         ---è¯·ä¸è¦å›å¤å¤§æ¦‚ã€å¯èƒ½ç­‰æ¨¡æ£±ä¸¤å¯çš„ç­”æ¡ˆã€‚
            """    
    client = ZhipuAI(api_key="927615462c6a5e9758e5b563a8b9003c.f2sbR2fSOxEqYzeN")
    answer = ""

# è°ƒç”¨å¤§æ¨¡å‹è¿›è¡Œæ–‡æ¡£ä¼˜åŒ–
    response = client.chat.completions.create(
        model="glm-4-plus",
        messages=[
            {"role": "system", "content": sys_prompt},
            {"role": "user", "content": user_prompt},
        ],
        temperature = kd_temperature,
        stream=True,
    )

    # ä½¿ç”¨ç”Ÿæˆå™¨é€å—å¤„ç†æµå¼å“åº”
    for chunk in response:
        content = chunk.choices[0].delta.content
        print(content)
        yield content  # ä½¿ç”¨yieldè¿”å›æ¯ä¸ªå—çš„å†…å®¹


if "retriel" not in st.session_state:
    st.session_state["retriel"] = ""
if clear_button:
    st.session_state["retriel"] = ""


tab1,tab2 = st.tabs(["çŸ¥è¯†åº“","æ£€ç´¢é—®ç­”"])
with tab1:
    col1,col2 = st.columns([1,2])
    with col1:        

        know_db_addr = st.text_area(label = "çŸ¥è¯†åº“çŸ¥è¯†æºæ–‡ä»¶æ–‡ä»¶å¤¹è·¯å¾„",placeholder="è¯·è¾“å…¥çŸ¥è¯†åº“æºæ–‡ä»¶æ–‡ä»¶å¤¹è·¯å¾„,linuxç³»ç»Ÿä»¥/å¼€å§‹")
              
        know_db_name = os.path.basename(know_db_addr)
        # st.divider()
        st.write(f"çŸ¥è¯†åº“åç§°ä¸º{know_db_name}")

        st.write("çŸ¥è¯†åº“æ–‡ä»¶ç»“æ„ä¸ºâ€œxxxxx/knowledge_database/å…·ä½“çŸ¥è¯†åº“æ–‡ä»¶å¤¹/çŸ¥è¯†æºæ–‡ä»¶çš„æ–‡ä»¶å¤¹ï¼ŒçŸ¥è¯†åº“åå­—_splittxt.pklï¼ŒçŸ¥è¯†åº“åå­—_splittxt.pklâ€ã€‚å…·ä½“çŸ¥è¯†åº“æ–‡ä»¶å¤¹åç§°å’ŒçŸ¥è¯†æºæ–‡ä»¶çš„æ–‡ä»¶å¤¹åç§°ä¸€è‡´ã€‚çŸ¥è¯†æºæ–‡ä»¶çš„æ–‡ä»¶å¤¹é‡Œé¢æ”¾çŸ¥è¯†æºæ–‡ä»¶.txtï¼›â€œçŸ¥è¯†åº“åå­—_splittxt.pklâ€æ–‡ä»¶æ˜¯åˆ†å‰²åçš„æ–‡æœ¬æ–‡ä»¶ï¼›â€œçŸ¥è¯†åº“åå­—_faissindex.faissâ€æ˜¯åˆ†å‰²æ–‡æœ¬å‘é‡åŒ–åå­˜å‚¨çš„faisså‘é‡æ•°æ®æ–‡ä»¶ ")
    
    with col2:
        
        if know_db_gene_button:
            know_retu = load_spilt_embedding_txt(kd_source_file_path = know_db_addr)        
            # st.text_area(label = "çŸ¥è¯†åº“åç§°",value = know_db_name)
            st.text_area(label = "çŸ¥è¯†åº“çŠ¶æ€",height = 120, value = know_retu["situation"])
            st.text_area(label = "çŸ¥è¯†åˆ†å‰²çŠ¶æ€",height = 250, value = (
    f"{know_retu['split_situation'][0]}\n\n"
    f"{know_retu['split_situation'][1]}\n\n"
    f"{know_retu['split_situation'][2]}"
))

            st.write(know_retu["faiss_situation"])
        else:
            # st.text_area(label = "çŸ¥è¯†åº“åç§°",value = "")
            st.text_area(label = "çŸ¥è¯†åº“çŠ¶æ€",height = 120, value = "")
            st.text_area(label = "çŸ¥è¯†åˆ†å‰²çŠ¶æ€",height = 200, value = "")
            st.write("å‘é‡æ•°æ®åº“çŠ¶æ€")
with tab2:
    col1,col2 = st.columns([1,2])
    with col1:
       
        ssssquery =st.text_area(label = "é—®é¢˜",placeholder="è¯·è¾“å…¥éœ€è¦æ£€ç´¢çš„é—®é¢˜")
        squery = [ssssquery]
        
        k = st.number_input("è¯·è¾“å…¥æ£€ç´¢ä¸ªæ•°",min_value = 1, max_value = 20,value = 5)
        
        # faiss_db = st.file_uploader("è¯·é€‰æ‹©å‘é‡æ•°æ®åº“XXX_faissindex.faissæ–‡ä»¶", type=['faiss'])
        faiss_db = st.text_area("è¯·è¾“å…¥å‘é‡æ•°æ®åº“çš„åœ°å€.faissæ–‡ä»¶")
        txt_path =  st.text_area("è¯·è¾“å…¥åˆ‡å‰²æ–‡ä»¶çš„åœ°å€.pklæ–‡ä»¶")
        # uploaded_file2 = st.file_uploader("è¯·é€‰æ‹©ä¸€ä¸ªåˆ†å‰²æ–‡æœ¬åº“XXX__splittxt.pklæ–‡ä»¶", type=['pkl'])
        # # å¦‚æœæ–‡ä»¶è¢«ä¸Šä¼ ï¼Œåˆ™åŠ è½½å¹¶æ˜¾ç¤ºå†…å®¹
        # if uploaded_file2 is not None:
        #     # ä½¿ç”¨ pickle åŠ è½½ä¸Šä¼ çš„æ–‡ä»¶
        #     txt_path = uploaded_file2
        # else:
        #     txt_path = ""
    
    with col2:
        
        if retri_button:
            if faiss_db != "" and txt_path != "":
                st.session_state["retriel"] = knoledge_retri(faiss_path=faiss_db,txt_path=txt_path,squery=squery,k=k)
        retre_results = st.text_area(label = "æ£€ç´¢ç»“æœ", height = 200 ,value = st.session_state["retriel"])

        if answ_button and retre_results!="":
            answ_gener = RAG_Answ(squery=squery,retre_result=retre_results,kd_temperature=kd_temperature,field=field)
            answ_txt = ""
            placeholder =st.empty()
            for trunk in answ_gener:
                if trunk != "":
                  answ_txt += trunk
                else:
                  answ_txt += "  "
                placeholder.text_area(label = "å¤§æ¨¡å‹ç­”æ¡ˆ", height = 250,value = answ_txt)
        else:
            st.text_area(label = "å¤§æ¨¡å‹ç­”æ¡ˆ",height = 250,value ="")
                
